{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "**Web Scraping:**\n",
    "Web scraping is the process of extracting data from websites. It involves fetching the web page's HTML code and then extracting and converting the relevant data into a structured format, such as a spreadsheet or database. Web scraping can be done manually, but it is often automated using programming languages like Python.\n",
    "\n",
    "**Why is it Used:**\n",
    "Web scraping is used for various purposes, including:\n",
    "\n",
    "1. **Data Collection:** Extracting data from websites for analysis and research.\n",
    "2. **Price Monitoring:** Monitoring and comparing prices of products on different e-commerce websites.\n",
    "3. **Competitor Analysis:** Gathering information about competitors, such as product offerings and pricing.\n",
    "\n",
    "# Q2: What are the different methods used for Web Scraping?\n",
    "\n",
    "There are various methods for web scraping, including:\n",
    "\n",
    "1. **Manual Copy-Pasting:** Copying and pasting data from a website to a local file.\n",
    "2. **Regular Expressions:** Using patterns to extract data from HTML.\n",
    "3. **HTML Parsing:** Parsing HTML using libraries like Beautiful Soup.\n",
    "4. **XPath:** Using XPath expressions to navigate and extract data from XML-like documents.\n",
    "5. **APIs:** Accessing data through APIs provided by websites.\n",
    "\n",
    "# Q3: What is Beautiful Soup? Why is it used?\n",
    "\n",
    "**Beautiful Soup:**\n",
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files. It provides Pythonic idioms for iterating, searching, and modifying the parse tree. Beautiful Soup sits on top of popular Python parsers like lxml and html5lib, allowing you to try out different parsing strategies or trade speed for flexibility.\n",
    "\n",
    "**Why is it used:**\n",
    "Beautiful Soup simplifies the process of scraping web pages by providing Pythonic ways to navigate, search, and modify the parse tree. It helps to handle malformed HTML, and it is widely used for web scraping tasks.\n",
    "\n",
    "# Q4: Why is Flask used in this Web Scraping project?\n",
    "\n",
    "**Flask:**\n",
    "Flask is a lightweight web framework for Python. It is commonly used for developing web applications, including those involving web scraping. In a web scraping project, Flask can be used to create a web interface for users to interact with the scraped data. It allows you to present the data in a user-friendly manner and provides a way for users to input parameters or receive the scraped data in a structured format.\n",
    "\n",
    "# Q5: Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "The AWS services used in this project can vary depending on the specific requirements. However, in a typical web scraping project hosted on AWS with Elastic Beanstalk and CodePipeline, you might use services like:\n",
    "\n",
    "1. **AWS Elastic Beanstalk:**\n",
    "   - **Use:** AWS Elastic Beanstalk is a fully managed service that makes it easy to deploy and run applications in multiple languages. It abstracts the complexity of managing infrastructure, allowing you to focus on your application. In this project, Elastic Beanstalk can host your web scraping script and Flask application, providing an easy way to scale and manage the application.\n",
    "\n",
    "2. **AWS CodePipeline:**\n",
    "   - **Use:** AWS CodePipeline is a continuous integration and continuous delivery (CI/CD) service. It automates the build, test, and deployment phases of your release process. In this project, CodePipeline can be configured to automatically deploy updates to your Elastic Beanstalk environment whenever changes are pushed to your source code repository. This streamlines the deployment process and ensures a consistent and automated release pipeline.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
